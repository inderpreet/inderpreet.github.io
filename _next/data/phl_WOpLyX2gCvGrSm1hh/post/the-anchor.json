{"pageProps":{"post":{"slug":"the-anchor","title":"Every System Tells Its Truth in Production","date":"2025-11-01","excerpt":"Production strips away comfortable illusions. It's where assumptions stop being hypothetical and start charging interest—revealing not just what we built, but what we actually designed.","author":{"name":"Inderpreet Singh","avatar":"IS"},"image":"/images/posts/post-anchor-splash-0.png","tags":["systems","production","engineering","reliability"],"likes":0,"comments":0,"content":"<p>A control system runs a hydraulic system for eighteen months without incidence. Then one morning, the hydraulic fluid leaks out from a hose and the system looses pressure which causes the system response to be sluggish. No trips, No alarms fire. The control panel continues executing its cycle. But as the fluid reserviors drain out over the next few days, the system starts to misbehave, and operations begin to fail. The system is eventually down and maintenance is notified but the damage is done and operation is down resulting in costs.</p>\n<p>The control system worked exactly as designed. It just wasn&#39;t designed for this.</p>\n<h1>Every System Tells Its Truth in Production</h1>\n<p>Most systems look reasonable on the happy path. The designed path. These systems behave themselves in demos and pass the developer&#39;s tests and even survive design reviews. Afterall, the developers have the best intentions in mind. And then they reach production and their intended customers. That is when the conversation take a turn.</p>\n<p>Production isn&#39;t just an environment—it&#39;s a crucible. Real machinery, real physics, real latency, real operators, real consequences. It&#39;s where assumptions stop being hypothetical and start charging interest. Where the difference between 100ms and 200ms isn&#39;t academic—it&#39;s the difference between a controlled stop and an emergency shutdown.</p>\n<p>Every system tells its truth there.</p>\n<h1>The Comfortable Lie of the Happy Path</h1>\n<p>The happy path is a useful fiction - an essential posion if you may. We need it to get anything built at all and for the fundamental truth that it lets us describe the intent. A composite of requirements translated into user stories or fairy-tale descriptions of how the user will interact with the system. It lets us romance the reason for the desired behaviour and reassures us that when a checklist is all done, we can finally ship and raise a glass to a job well done.</p>\n<p>It starts with a concise set of words on a document and then evolves and over time, teams begin to mistake the happy path for reality. Diagrams become promises. Tests become guarantees. Architecture documents become a form of reassurance.</p>\n<p>What gets less attention is everything living just outside that path: sensors that drift over months rather than fail outright or even sensors installed so that they jittern instead of producing a constant output, networks that don&#39;t drop packets but add 50ms of jitter under load, operators who develop workarounds that bypass safety interlocks, physical processes that couple in ways the control model doesn&#39;t account for.</p>\n<p>These are not edge cases. <strong>They are the system.</strong></p>\n<h1>What “Truth” Actually Means</h1>\n<p>When I say a system tells its truth in production, I don&#39;t mean it suddenly becomes malicious or broken. I mean it becomes honest about what it actually is—not what we documented it to be.</p>\n<p>Think of it like this: in the lab, you&#39;re having a conversation with your system. You command a valve to open and it complies. You trigger an interlock and it responds. You&#39;re speaking to it in a controlled environment, with calibrated instruments, asking it controlled questions.</p>\n<p>Production is where the system starts talking back.</p>\n<p>It reveals what it actually depends on—not just the 24VDC supply you specified, but the quality of that supply under varying loads, the grounding scheme you inherited, the EMI from the VFD three panels over. It shows which failures it tolerates (a single missed Communication frame) and which it amplifies (a watchdog timeout that cascades into a full line stop). It exposes where responsibility is clear (who owns the PLC code) and where it diffuses (who decides when to replace aging sensors).</p>\n<p>And here&#39;s what makes this uncomfortable: production reveals not just technical design, but operational reality. Maintenance schedules that drift. Calibration records that age. Tribal knowledge about &quot;the weird thing it does on cold starts.&quot; Decision-making under the pressure of downtime costs.</p>\n<p>None of this is visible in a clean system architecture diagram.</p>\n<h1>“The System Worked Exactly as Designed”</h1>\n<p>This sentence appears often in incident reports, usually as a way to end a conversation. But it&#39;s almost always true—and deeply misunderstood.</p>\n<p>Most failures are not the result of a single fault. They are the natural outcome of tradeoffs made under budget constraints, complexity accumulated across multiple integration phases, and risk accepted implicitly because making it explicit would have delayed commissioning.</p>\n<p>The system worked exactly as designed. The problem is that the design included far more than firmware, software and wiring diagrams. It included unspoken assumptions about how operators would interact with HMIs, implicit bets about which sensors wouldn&#39;t drift simultaneously or would be installed correctly, and organizational patterns that made certain kinds of information invisible during shift handoffs.</p>\n<p>The control system with the leaky hydraulic fluid? It was designed to operate the hydraulics and ignore response time in favour of supporting different models of pumps. That was a conscious choice, documented and reviewed. What wasn&#39;t designed was the specific failure mode where a sluggish response of the mechanics, reported plausible-but-wrong values that fell within acceptance bounds, or the maintenance team&#39;s inability to correlate subtle performance degradation, or the absence of any pressure monitoring in the original specification.<br>The system told the truth about all of it.</p>\n<h1>Why Production Is Uncomfortable</h1>\n<p>Production removes the illusion of control.</p>\n<p>You no longer get to choose when failures occur, how visible they are, what else is happening simultaneously, or how much time you have to respond. It forces decisions to be made with incomplete telemetry, by fatigued operators, with production managers asking for ETAs.</p>\n<p>That is not a weakness of production. That is its value.</p>\n<p>This is where experience is formed—not by avoiding failures, but by learning what survives them. It&#39;s where you discover which of your redundancies were weight-bearing and which were decorative. It&#39;s where you learn the difference between a system that degrades gracefully and one that simply hasn&#39;t encountered the right combination of conditions yet.</p>\n<p>In embedded and IIoT systems, this matters more. You can&#39;t just roll back a deployment. You can&#39;t hotfix firmware on a system that&#39;s safety-critical without a maintenance window. Your &quot;users&quot; are 50-ton machines that cost $10,000 per hour of downtime. The feedback loop is measured in months, not minutes.</p>\n<h1>This Is Not a Blog About Tools</h1>\n<p>Tools matter. Microcontrollers matter. Protocols matter. Fieldbus architectures matter. Cloud architectures matter.</p>\n<p>But they are rarely the reason systems fail in production.</p>\n<p>Systems fail because graceful degradation was an afterthought, ownership boundaries were unclear between firmware and mechanical teams, incentives were misaligned between commissioning speed and long-term reliability, risks were known but unspoken during design reviews, and complexity grew faster than documentation—or understanding.</p>\n<p>Those are design problems. Judgment problems. Responsibility problems.</p>\n<p>That is what this space is about.</p>\n<h1>So Why This Exists?</h1>\n<p>Off the Happy Path is a collection of observations, essays, and stories from production systems—embedded firmware, IIoT platforms, control systems, and the organizations that build and operate them.</p>\n<p>It is not a tutorial blog. It will not explain fundamentals that datasheets and standards already cover well. It will not optimize for engagement or outrage.</p>\n<p>It exists to name things that are usually felt but not discussed. To talk about systems as they behave, not as we wish they would. To capture lessons that tend to surface only after something breaks—and sometimes only after we&#39;ve stopped to actually listen.</p>\n<h1>A Final Thought</h1>\n<p>If a system has never surprised you in production, one of two things is true: either it has not been in production long enough, or you were not listening closely when it spoke.</p>\n<p>Because eventually, every system does. It tells its truth.</p>\n<p>The question is whether we&#39;re ready to hear it.</p>\n","rawContent":"\r\nA control system runs a hydraulic system for eighteen months without incidence. Then one morning, the hydraulic fluid leaks out from a hose and the system looses pressure which causes the system response to be sluggish. No trips, No alarms fire. The control panel continues executing its cycle. But as the fluid reserviors drain out over the next few days, the system starts to misbehave, and operations begin to fail. The system is eventually down and maintenance is notified but the damage is done and operation is down resulting in costs.\r\n\r\nThe control system worked exactly as designed. It just wasn't designed for this.\r\n\r\n# Every System Tells Its Truth in Production\r\n\r\nMost systems look reasonable on the happy path. The designed path. These systems behave themselves in demos and pass the developer's tests and even survive design reviews. Afterall, the developers have the best intentions in mind. And then they reach production and their intended customers. That is when the conversation take a turn.\r\n\r\nProduction isn't just an environment—it's a crucible. Real machinery, real physics, real latency, real operators, real consequences. It's where assumptions stop being hypothetical and start charging interest. Where the difference between 100ms and 200ms isn't academic—it's the difference between a controlled stop and an emergency shutdown.\r\n\r\nEvery system tells its truth there.\r\n\r\n# The Comfortable Lie of the Happy Path\r\n\r\nThe happy path is a useful fiction - an essential posion if you may. We need it to get anything built at all and for the fundamental truth that it lets us describe the intent. A composite of requirements translated into user stories or fairy-tale descriptions of how the user will interact with the system. It lets us romance the reason for the desired behaviour and reassures us that when a checklist is all done, we can finally ship and raise a glass to a job well done.\r\n\r\nIt starts with a concise set of words on a document and then evolves and over time, teams begin to mistake the happy path for reality. Diagrams become promises. Tests become guarantees. Architecture documents become a form of reassurance.\r\n\r\nWhat gets less attention is everything living just outside that path: sensors that drift over months rather than fail outright or even sensors installed so that they jittern instead of producing a constant output, networks that don't drop packets but add 50ms of jitter under load, operators who develop workarounds that bypass safety interlocks, physical processes that couple in ways the control model doesn't account for.\r\n\r\nThese are not edge cases. **They are the system.**\r\n\r\n# What “Truth” Actually Means\r\n\r\nWhen I say a system tells its truth in production, I don't mean it suddenly becomes malicious or broken. I mean it becomes honest about what it actually is—not what we documented it to be.\r\n\r\nThink of it like this: in the lab, you're having a conversation with your system. You command a valve to open and it complies. You trigger an interlock and it responds. You're speaking to it in a controlled environment, with calibrated instruments, asking it controlled questions.\r\n\r\nProduction is where the system starts talking back.\r\n\r\nIt reveals what it actually depends on—not just the 24VDC supply you specified, but the quality of that supply under varying loads, the grounding scheme you inherited, the EMI from the VFD three panels over. It shows which failures it tolerates (a single missed Communication frame) and which it amplifies (a watchdog timeout that cascades into a full line stop). It exposes where responsibility is clear (who owns the PLC code) and where it diffuses (who decides when to replace aging sensors).\r\n\r\nAnd here's what makes this uncomfortable: production reveals not just technical design, but operational reality. Maintenance schedules that drift. Calibration records that age. Tribal knowledge about \"the weird thing it does on cold starts.\" Decision-making under the pressure of downtime costs.\r\n\r\nNone of this is visible in a clean system architecture diagram.\r\n\r\n# “The System Worked Exactly as Designed”\r\n\r\nThis sentence appears often in incident reports, usually as a way to end a conversation. But it's almost always true—and deeply misunderstood.\r\n\r\nMost failures are not the result of a single fault. They are the natural outcome of tradeoffs made under budget constraints, complexity accumulated across multiple integration phases, and risk accepted implicitly because making it explicit would have delayed commissioning.\r\n\r\nThe system worked exactly as designed. The problem is that the design included far more than firmware, software and wiring diagrams. It included unspoken assumptions about how operators would interact with HMIs, implicit bets about which sensors wouldn't drift simultaneously or would be installed correctly, and organizational patterns that made certain kinds of information invisible during shift handoffs.\r\n\r\nThe control system with the leaky hydraulic fluid? It was designed to operate the hydraulics and ignore response time in favour of supporting different models of pumps. That was a conscious choice, documented and reviewed. What wasn't designed was the specific failure mode where a sluggish response of the mechanics, reported plausible-but-wrong values that fell within acceptance bounds, or the maintenance team's inability to correlate subtle performance degradation, or the absence of any pressure monitoring in the original specification.\r\nThe system told the truth about all of it.\r\n\r\n# Why Production Is Uncomfortable\r\n\r\nProduction removes the illusion of control.\r\n\r\nYou no longer get to choose when failures occur, how visible they are, what else is happening simultaneously, or how much time you have to respond. It forces decisions to be made with incomplete telemetry, by fatigued operators, with production managers asking for ETAs.\r\n\r\nThat is not a weakness of production. That is its value.\r\n\r\nThis is where experience is formed—not by avoiding failures, but by learning what survives them. It's where you discover which of your redundancies were weight-bearing and which were decorative. It's where you learn the difference between a system that degrades gracefully and one that simply hasn't encountered the right combination of conditions yet.\r\n\r\nIn embedded and IIoT systems, this matters more. You can't just roll back a deployment. You can't hotfix firmware on a system that's safety-critical without a maintenance window. Your \"users\" are 50-ton machines that cost $10,000 per hour of downtime. The feedback loop is measured in months, not minutes.\r\n\r\n# This Is Not a Blog About Tools\r\n\r\nTools matter. Microcontrollers matter. Protocols matter. Fieldbus architectures matter. Cloud architectures matter.\r\n\r\nBut they are rarely the reason systems fail in production.\r\n\r\nSystems fail because graceful degradation was an afterthought, ownership boundaries were unclear between firmware and mechanical teams, incentives were misaligned between commissioning speed and long-term reliability, risks were known but unspoken during design reviews, and complexity grew faster than documentation—or understanding.\r\n\r\nThose are design problems. Judgment problems. Responsibility problems.\r\n\r\nThat is what this space is about.\r\n\r\n# So Why This Exists?\r\n\r\nOff the Happy Path is a collection of observations, essays, and stories from production systems—embedded firmware, IIoT platforms, control systems, and the organizations that build and operate them.\r\n\r\nIt is not a tutorial blog. It will not explain fundamentals that datasheets and standards already cover well. It will not optimize for engagement or outrage.\r\n\r\nIt exists to name things that are usually felt but not discussed. To talk about systems as they behave, not as we wish they would. To capture lessons that tend to surface only after something breaks—and sometimes only after we've stopped to actually listen.\r\n\r\n# A Final Thought\r\n\r\nIf a system has never surprised you in production, one of two things is true: either it has not been in production long enough, or you were not listening closely when it spoke.\r\n\r\nBecause eventually, every system does. It tells its truth.\r\n\r\nThe question is whether we're ready to hear it."}},"__N_SSG":true}
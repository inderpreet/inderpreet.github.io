<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>The Happy Path Is a Lie We Tell Ourselves | Layered Systems</title><meta name="title" content="The Happy Path Is a Lie We Tell Ourselves | Layered Systems"/><meta name="description" content="Design reviews reward optimism. Test environments validate assumptions. And somewhere between approval and deployment, we forget that we&#x27;re building systems for a world that doesn&#x27;t care about our diagrams."/><meta name="keywords" content="systems, design, production, failure"/><meta name="author" content="Inderpreet Singh"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:type" content="website"/><meta property="og:url" content="https://inderpreet.github.io"/><meta property="og:title" content="The Happy Path Is a Lie We Tell Ourselves | Layered Systems"/><meta property="og:description" content="Design reviews reward optimism. Test environments validate assumptions. And somewhere between approval and deployment, we forget that we&#x27;re building systems for a world that doesn&#x27;t care about our diagrams."/><meta property="og:image" content="/og-image.jpg"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:url" content="https://inderpreet.github.io"/><meta property="twitter:title" content="The Happy Path Is a Lie We Tell Ourselves | Layered Systems"/><meta property="twitter:description" content="Design reviews reward optimism. Test environments validate assumptions. And somewhere between approval and deployment, we forget that we&#x27;re building systems for a world that doesn&#x27;t care about our diagrams."/><meta property="twitter:image" content="/og-image.jpg"/><meta name="robots" content="index, follow"/><meta name="language" content="English"/><link rel="canonical" href="https://inderpreet.github.io"/><meta name="next-head-count" content="20"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><meta name="theme-color" content="#000000"/><link rel="preload" href="/_next/static/css/1d29b84bfc5354c8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/1d29b84bfc5354c8.css" data-n-g=""/><link rel="preload" href="/_next/static/css/0fdd858d31bddfca.css" as="style"/><link rel="stylesheet" href="/_next/static/css/0fdd858d31bddfca.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-639aa3d8bfe7ee72.js" defer=""></script><script src="/_next/static/chunks/framework-64ad27b21261a9ce.js" defer=""></script><script src="/_next/static/chunks/main-d979f5fb3aa68004.js" defer=""></script><script src="/_next/static/chunks/pages/_app-20693b9d02de5813.js" defer=""></script><script src="/_next/static/chunks/666-58cfeb78f799b3ee.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-388991efceb2e5b5.js" defer=""></script><script src="/_next/static/phl_WOpLyX2gCvGrSm1hh/_buildManifest.js" defer=""></script><script src="/_next/static/phl_WOpLyX2gCvGrSm1hh/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="Layout_container__l2gjk"><header class="Layout_header__8XhYm"><div class="Layout_headerContent__06wDW"><nav class="Layout_nav__qOLUE "><a href="/">Home</a><a href="/about">About</a><div class="Layout_dropdown__z3jRI"><button class="Layout_dropdownToggle__WdMTA" aria-expanded="false" aria-haspopup="true">Resources<svg width="12" height="12" viewBox="0 0 12 12" fill="currentColor" style="margin-left:0.25rem;transform:rotate(0deg);transition:transform 0.2s"><path d="M2 4l4 4 4-4" stroke="currentColor" stroke-width="2" fill="none"></path></svg></button><div class="Layout_dropdownMenu__zEIeU "><a href="/monitor" class="Layout_dropdownItem__tEDBv"><span class="Layout_dropdownIcon__fA6Ww">üéõÔ∏è</span><div><div class="Layout_dropdownItemTitle__VcVEY">System Monitor</div><div class="Layout_dropdownItemDesc__DjI_j">Real-time dashboard</div></div></a><a href="https://github.com/inderpreet" target="_blank" rel="noopener noreferrer" class="Layout_dropdownItem__tEDBv"><span class="Layout_dropdownIcon__fA6Ww">üíª</span><div><div class="Layout_dropdownItemTitle__VcVEY">GitHub</div><div class="Layout_dropdownItemDesc__DjI_j">View my repositories</div></div></a><div class="Layout_dropdownDivider__ySCu0"></div><a href="/docs" class="Layout_dropdownItem__tEDBv"><span class="Layout_dropdownIcon__fA6Ww">üìö</span><div><div class="Layout_dropdownItemTitle__VcVEY">Documentation</div><div class="Layout_dropdownItemDesc__DjI_j">Guides &amp; tutorials</div></div></a><a href="#" class="Layout_dropdownItem__tEDBv"><span class="Layout_dropdownIcon__fA6Ww">üöÄ</span><div><div class="Layout_dropdownItemTitle__VcVEY">Projects</div><div class="Layout_dropdownItemDesc__DjI_j">Explore my work</div></div></a></div></div></nav><div class="Layout_logoSection__xngcy"><h1 class="Layout_logo__Yfd0y"><a href="/">Layered Systems</a></h1><p class="Layout_tagline__pRBfO">Engineering judgment, one layer at a time.</p></div><div class="Layout_socialIcons__8_CJc"><button class="ThemeToggle_themeToggle__Lxt_p" aria-label="Toggle theme"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="5"></circle></svg></button><a href="https://github.com/inderpreet" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg></a><a href="https://twitter.com/ip_v1" target="_blank" rel="noopener noreferrer" aria-label="Twitter"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M23.953 4.57a10 10 0 01-2.825.775 4.958 4.958 0 002.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 00-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 00-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 01-2.228-.616v.06a4.923 4.923 0 003.946 4.827 4.996 4.996 0 01-2.212.085 4.936 4.936 0 004.604 3.417 9.867 9.867 0 01-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 007.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0024 4.59z"></path></svg></a><a href="https://linkedin.com/in/inderpreets" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></a></div><button class="Layout_mobileMenuButton__nLMRy" aria-label="Toggle menu"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></header><main class="Layout_main__BqQ1G"><div class="Post_postContainer__1nAIq"><article class="Post_post__1KH4p"><div class="Post_postHeader__VS2xC"><div class="Post_authorSection__JpQiF"><div class="Post_avatarLarge__YO5z5">IS</div><div><h3 class="Post_authorName__3jNxf">Inderpreet Singh</h3><time class="Post_date__YGL_Q">2025-12-01</time></div></div></div><div class="Post_featuredImage__CRWk2"><img src="/images/posts/design-review.png" alt="The Happy Path Is a Lie We Tell Ourselves"/></div><div class="Post_postContent__EmxdX"><h1 class="Post_title__pen_7">The Happy Path Is a Lie We Tell Ourselves</h1><div class="Post_tags__PFaKf"><span class="Post_tag__jmLTM">#<!-- -->systems</span><span class="Post_tag__jmLTM">#<!-- -->design</span><span class="Post_tag__jmLTM">#<!-- -->production</span><span class="Post_tag__jmLTM">#<!-- -->failure</span></div><div class="Post_content__aWM2C"><p>Three engineers sit in a design review for a new temperature monitoring system. The architecture is clean: sensors report to edge controllers, controllers aggregate to a gateway, gateway publishes to the cloud. Redundancy at every layer. Graceful degradation clearly marked on the diagram.</p>
<p>Someone asks: &quot;What happens if the gateway loses connectivity?&quot;</p>
<p>&quot;It buffers locally for up to 72 hours,&quot; comes the answer. &quot;More than enough for any reasonable outage.&quot;</p>
<p>Everyone nods. The design is approved.</p>
<p>Two years later, a cellular provider pushes a configuration update that breaks connectivity for five days. The gateway&#39;s flash memory fills in eighteen hours. When connectivity returns, 96 hours of critical temperature data is gone. The system worked exactly as designed‚Äîit just wasn&#39;t designed for this.</p>
<p>The happy path is seductive because it lets us move forward. But it&#39;s also a lie we tell ourselves, and design reviews are where that lie gets institutionalized.</p>
<h2>Why Design Reviews Reward Optimism</h2>
<p>Design reviews are supposed to find problems. In practice, they often do the opposite: they create consensus around the assumption that problems won&#39;t happen.</p>
<p>Here&#39;s how it works:</p>
<p>You present a design. You show the nominal flow. You mark the error paths. You explain the redundancies. And then the questions come‚Äîbut they come in a specific form: &quot;What if X fails?&quot; You answer with your contingency for X. &quot;What if Y happens?&quot; You show your handling of Y.</p>
<p>Each question asked and answered creates the illusion that you&#39;ve covered the space of possible failures. What&#39;s harder to see is the space of failures that weren&#39;t asked about‚Äînot because they&#39;re impossible, but because they&#39;re hard to imagine from a conference room.</p>
<p>The cellular configuration update that breaks connectivity for five days isn&#39;t a question anyone asks, because connectivity outages are supposed to last hours, not days. The sensor that doesn&#39;t fail cleanly but drifts slowly enough to stay within acceptance bounds for months isn&#39;t on the checklist, because sensors are supposed to either work or fail obviously. The operator who learns to bypass an interlock because it trips too often during valid operations isn&#39;t in the room, because we&#39;re reviewing technical design, not operational reality.</p>
<p>Design reviews optimize for demonstrable coverage of known failure modes. They reward the ability to show that you&#39;ve thought about things. But &quot;thinking about things&quot; is different from designing for them, and both are different from experiencing them.</p>
<p>This creates a subtle bias: the designs that pass review most easily are the ones that look most robust on paper. Clean boundaries. Clear error handling. Documented assumptions. The designs that acknowledge fundamental uncertainties‚Äî&quot;we don&#39;t know how operators will actually use this,&quot; &quot;we can&#39;t predict how this will interact with the legacy system at scale&quot;‚Äîfeel incomplete. They sound like excuses.</p>
<p>So we learn to present certainty. We learn to have answers. And slowly, the happy path becomes the only path we&#39;re willing to defend.</p>
<h2>How Organizations Institutionalize Blind Spots</h2>
<p>Individual engineers know the happy path is optimistic. But organizations have a way of turning individual caution into collective blindness.</p>
<p>Consider what happens after that design review. The design is approved. It goes into a requirements document. The requirements become tasks. The tasks become sprints. And at each translation, something is lost.</p>
<p>The subtle caveat‚Äî&quot;this assumes network partitions are transient&quot;‚Äîbecomes &quot;handles network failures.&quot; The hedge‚Äî&quot;buffering capacity should be sufficient for typical outages&quot;‚Äîbecomes &quot;72-hour buffer.&quot; The uncertainty‚Äî&quot;we&#39;ll need to monitor how this behaves under load&quot;‚Äîbecomes a checkbox: &quot;performance tested.&quot;</p>
<p>This isn&#39;t malice. It&#39;s how organizations create actionable plans from ambiguous reality. But in the process, assumptions get promoted to facts, and facts get encoded into architecture.</p>
<p>Worse, once something is designed and built, it becomes expensive to question. Not just financially expensive‚Äîpolitically expensive. The team that built it has invested in it. Managers have reported progress on it. Customers have been promised it. To say &quot;we need to rethink this&quot; is to say all that investment might have been misdirected.</p>
<p>So instead, we add compensating controls. We build monitoring. We write runbooks. We train operators. Each addition reinforces the original design rather than questioning it. We&#39;re not asking &quot;should this system exist in this form?&quot; We&#39;re asking &quot;how do we make this system work?&quot;</p>
<p>I&#39;ve sat in meetings where everyone in the room privately knew a system was brittle, but no one said it directly because the system was already in production and replacing it would be a six-month project. Instead, we talked about &quot;hardening&quot; and &quot;resilience improvements&quot;‚Äîlanguage that suggested we were making something robust rather than patching something fundamentally fragile.</p>
<p>The organization&#39;s immune system had learned to reject the observation that the system was designed wrong, because accepting that observation would require acknowledging that a lot of other decisions were also wrong.</p>
<h2>Most Failures Are Designed</h2>
<p>Here&#39;s an uncomfortable truth: most production failures aren&#39;t accidents. They&#39;re not the result of bugs that slipped through testing or edge cases that no one thought of.</p>
<p>They&#39;re the inevitable outcome of decisions made under constraints.</p>
<p>That temperature monitoring system that lost 96 hours of data? The decision to use flash memory with limited write endurance was made to hit a cost target. The decision to buffer for 72 hours was made based on historical uptime data from a different cellular provider. The decision not to implement hierarchical buffering (edge ‚Üí gateway ‚Üí cloud) was made to keep the architecture simple and shippable.</p>
<p>None of those were wrong decisions in isolation. Given the constraints‚Äîbudget, schedule, what was known at the time‚Äîthey were defensible. Reasonable, even.</p>
<p>But they were decisions, not accidents. And decisions have consequences that aren&#39;t always visible until they compound.</p>
<p>This is what I mean when I say most failures are designed. Not that anyone set out to build a fragile system, but that fragility is often the natural result of optimizing for other things: speed, cost, simplicity, familiarity.</p>
<p>The difference between a bug and a decision is that bugs can be fixed. Decisions are encoded into the architecture. They become load-bearing assumptions. You can&#39;t fix them without rethinking the system.</p>
<p>When an incident review concludes &quot;the system worked as designed, but we didn&#39;t anticipate this scenario,&quot; what they&#39;re really saying is: &quot;we made tradeoffs, and this is what we traded away.&quot;</p>
<p>The question is whether we&#39;re honest about what we&#39;re trading. Most of the time, we&#39;re not‚Äîbecause being honest would make it harder to get the design approved.</p>
<h2>Why Test, Staging, and Simulation Always Mislead</h2>
<p>Every environment before production is a curated experience.</p>
<p>Test environments use clean data. Staging uses a subset of production scale. Simulations use models that abstract away complexity. Even load testing is fundamentally artificial‚Äîyou generate the load, you choose when to apply it, you know what you&#39;re testing for.</p>
<p>This isn&#39;t a criticism of testing. Testing is essential. But it&#39;s also fundamentally limited, and we consistently underestimate how limited it is.</p>
<p>Here&#39;s what test environments can&#39;t show you:</p>
<p><strong>They can&#39;t show you emergent behavior.</strong> That interaction between the VFD noise and the CAN bus that only manifests when both systems are under load and the ambient temperature is above 30¬∞C? Your test bench runs at 22¬∞C with one system at a time.</p>
<p><strong>They can&#39;t show you operational reality.</strong> The operator who learned that if you cycle the power on the HMI in a specific sequence, you can temporarily bypass an error condition that otherwise requires a maintenance window? They discovered that in production, under pressure, when the line manager was demanding a workaround.</p>
<p><strong>They can&#39;t show you the full dependency graph.</strong> You tested integration with the ERP system. You didn&#39;t test integration with the ERP system while the network team is doing maintenance and traffic is rerouting through a secondary path with higher latency and the backup MES is handling requests because the primary is being patched.</p>
<p><strong>They can&#39;t show you time.</strong> That sensor calibration drift that takes six months to become problematic? Your acceptance test runs for six hours.</p>
<p><strong>They can&#39;t show you organizational dynamics.</strong> Who gets called when something ambiguous happens at 2 AM? Who has the authority to make the call to shut down the line? Who actually knows where the documentation is? None of that exists in staging.</p>
<p>Production is the only environment where all the variables are real, all at once, without anyone curating the experience.</p>
<h2>What Production Pressure Reveals That Design Never Does</h2>
<p>There&#39;s a specific kind of knowledge that only emerges under production pressure, and it has nothing to do with technical design.</p>
<p>It&#39;s the knowledge of what actually matters.</p>
<p>In design, everything matters equally. Every requirement is important. Every failure mode is worth handling. Every dependency is documented. But in production, under time pressure, with costs accumulating, you discover very quickly what&#39;s truly critical and what was just conceptually important.</p>
<p>You discover that the &quot;critical&quot; alert that fires three times a day gets ignored, while the informal message in Slack from the night shift operator gets immediate attention because everyone knows that operator only speaks up when something is genuinely wrong.</p>
<p>You discover that the official escalation path‚Äîsubmit a ticket, wait for triage, get assigned to the on-call engineer‚Äîis too slow, and there&#39;s an unofficial path where certain people have certain phone numbers and that&#39;s what actually gets used when things are breaking.</p>
<p>You discover that the monitoring dashboard everyone insisted on building never gets looked at during incidents, but everyone opens the same three SSH sessions to check the same three log files because that&#39;s where the useful information actually lives.</p>
<p>You discover that the runbook that took weeks to write is useless because it assumes you have time to read it, and in production you don&#39;t‚Äîso people fall back on intuition, pattern matching, and educated guesses.</p>
<p>None of this is visible during design because design happens in an environment where time is less expensive and mistakes are reversible. Production pressure doesn&#39;t just reveal technical problems. It reveals organizational truth.</p>
<p>It shows you which abstractions hold up and which ones collapse. It shows you where authority actually lies versus where the org chart says it lies. It shows you which skills matter‚Äîand they&#39;re often not the ones that got people promoted.</p>
<h2>What This Means for How We Design</h2>
<p>I&#39;m not arguing that we should abandon design reviews or testing or staging environments. They serve a purpose. The problem is that we treat them as validation rather than exploration.</p>
<p>We treat passing a design review as evidence that the design is good. It&#39;s not. It&#39;s evidence that the design is defensible given what we know now, in this room, without production pressure.</p>
<p>We treat staging as a high-fidelity simulation of production. It&#39;s not. It&#39;s a curated environment that shares some properties with production and systematically excludes others.</p>
<p>If we were honest about this, we&#39;d design differently. We&#39;d spend less energy trying to anticipate every failure mode and more energy building systems that can be understood and modified when inevitably surprising failures occur.</p>
<p>We&#39;d document not just what the system does, but what we assumed about the environment it operates in. Not as a CYA exercise, but as a genuine artifact that helps the next person understand what we were thinking‚Äîand where we were probably wrong.</p>
<p>We&#39;d treat the first six months in production not as &quot;stabilization&quot; but as &quot;learning what we actually built&quot;‚Äîbecause that&#39;s what it is.</p>
<p>The happy path isn&#39;t useless. It&#39;s necessary to ship anything at all. But it&#39;s a lie we tell ourselves to make progress in the face of uncertainty.</p>
<p>The question is whether we remember it&#39;s a lie‚Äîor whether we start believing it.</p>
<p>Because the system will tell the truth eventually.</p>
<p>It always does.</p>
</div></div><div class="Post_backLink__n_9IU"><a href="/">‚Üê Back to Feed</a></div></article></div></main><footer class="Layout_footer__3v8iv"><p>¬© 2025 Layered Systems - Engineering judgment, one layer at a time.</p><div class="Layout_socialLinks__WZeQy"><a href="https://github.com/inderpreet" target="_blank" rel="noopener noreferrer">GitHub</a><a href="https://twitter.com/ip_v1" target="_blank" rel="noopener noreferrer">Twitter</a><a href="https://instagram.com/ip_v1" target="_blank" rel="noopener noreferrer">Instagram</a><a href="https://linkedin.com" target="_blank" rel="noopener noreferrer">LinkedIn</a></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"slug":"the-happy-post-lie","title":"The Happy Path Is a Lie We Tell Ourselves","date":"2025-12-01","excerpt":"Design reviews reward optimism. Test environments validate assumptions. And somewhere between approval and deployment, we forget that we're building systems for a world that doesn't care about our diagrams.","author":{"name":"Inderpreet Singh","avatar":"IS"},"image":"/images/posts/design-review.png","tags":["systems","design","production","failure"],"likes":0,"comments":0,"content":"\u003cp\u003eThree engineers sit in a design review for a new temperature monitoring system. The architecture is clean: sensors report to edge controllers, controllers aggregate to a gateway, gateway publishes to the cloud. Redundancy at every layer. Graceful degradation clearly marked on the diagram.\u003c/p\u003e\n\u003cp\u003eSomeone asks: \u0026quot;What happens if the gateway loses connectivity?\u0026quot;\u003c/p\u003e\n\u003cp\u003e\u0026quot;It buffers locally for up to 72 hours,\u0026quot; comes the answer. \u0026quot;More than enough for any reasonable outage.\u0026quot;\u003c/p\u003e\n\u003cp\u003eEveryone nods. The design is approved.\u003c/p\u003e\n\u003cp\u003eTwo years later, a cellular provider pushes a configuration update that breaks connectivity for five days. The gateway\u0026#39;s flash memory fills in eighteen hours. When connectivity returns, 96 hours of critical temperature data is gone. The system worked exactly as designed‚Äîit just wasn\u0026#39;t designed for this.\u003c/p\u003e\n\u003cp\u003eThe happy path is seductive because it lets us move forward. But it\u0026#39;s also a lie we tell ourselves, and design reviews are where that lie gets institutionalized.\u003c/p\u003e\n\u003ch2\u003eWhy Design Reviews Reward Optimism\u003c/h2\u003e\n\u003cp\u003eDesign reviews are supposed to find problems. In practice, they often do the opposite: they create consensus around the assumption that problems won\u0026#39;t happen.\u003c/p\u003e\n\u003cp\u003eHere\u0026#39;s how it works:\u003c/p\u003e\n\u003cp\u003eYou present a design. You show the nominal flow. You mark the error paths. You explain the redundancies. And then the questions come‚Äîbut they come in a specific form: \u0026quot;What if X fails?\u0026quot; You answer with your contingency for X. \u0026quot;What if Y happens?\u0026quot; You show your handling of Y.\u003c/p\u003e\n\u003cp\u003eEach question asked and answered creates the illusion that you\u0026#39;ve covered the space of possible failures. What\u0026#39;s harder to see is the space of failures that weren\u0026#39;t asked about‚Äînot because they\u0026#39;re impossible, but because they\u0026#39;re hard to imagine from a conference room.\u003c/p\u003e\n\u003cp\u003eThe cellular configuration update that breaks connectivity for five days isn\u0026#39;t a question anyone asks, because connectivity outages are supposed to last hours, not days. The sensor that doesn\u0026#39;t fail cleanly but drifts slowly enough to stay within acceptance bounds for months isn\u0026#39;t on the checklist, because sensors are supposed to either work or fail obviously. The operator who learns to bypass an interlock because it trips too often during valid operations isn\u0026#39;t in the room, because we\u0026#39;re reviewing technical design, not operational reality.\u003c/p\u003e\n\u003cp\u003eDesign reviews optimize for demonstrable coverage of known failure modes. They reward the ability to show that you\u0026#39;ve thought about things. But \u0026quot;thinking about things\u0026quot; is different from designing for them, and both are different from experiencing them.\u003c/p\u003e\n\u003cp\u003eThis creates a subtle bias: the designs that pass review most easily are the ones that look most robust on paper. Clean boundaries. Clear error handling. Documented assumptions. The designs that acknowledge fundamental uncertainties‚Äî\u0026quot;we don\u0026#39;t know how operators will actually use this,\u0026quot; \u0026quot;we can\u0026#39;t predict how this will interact with the legacy system at scale\u0026quot;‚Äîfeel incomplete. They sound like excuses.\u003c/p\u003e\n\u003cp\u003eSo we learn to present certainty. We learn to have answers. And slowly, the happy path becomes the only path we\u0026#39;re willing to defend.\u003c/p\u003e\n\u003ch2\u003eHow Organizations Institutionalize Blind Spots\u003c/h2\u003e\n\u003cp\u003eIndividual engineers know the happy path is optimistic. But organizations have a way of turning individual caution into collective blindness.\u003c/p\u003e\n\u003cp\u003eConsider what happens after that design review. The design is approved. It goes into a requirements document. The requirements become tasks. The tasks become sprints. And at each translation, something is lost.\u003c/p\u003e\n\u003cp\u003eThe subtle caveat‚Äî\u0026quot;this assumes network partitions are transient\u0026quot;‚Äîbecomes \u0026quot;handles network failures.\u0026quot; The hedge‚Äî\u0026quot;buffering capacity should be sufficient for typical outages\u0026quot;‚Äîbecomes \u0026quot;72-hour buffer.\u0026quot; The uncertainty‚Äî\u0026quot;we\u0026#39;ll need to monitor how this behaves under load\u0026quot;‚Äîbecomes a checkbox: \u0026quot;performance tested.\u0026quot;\u003c/p\u003e\n\u003cp\u003eThis isn\u0026#39;t malice. It\u0026#39;s how organizations create actionable plans from ambiguous reality. But in the process, assumptions get promoted to facts, and facts get encoded into architecture.\u003c/p\u003e\n\u003cp\u003eWorse, once something is designed and built, it becomes expensive to question. Not just financially expensive‚Äîpolitically expensive. The team that built it has invested in it. Managers have reported progress on it. Customers have been promised it. To say \u0026quot;we need to rethink this\u0026quot; is to say all that investment might have been misdirected.\u003c/p\u003e\n\u003cp\u003eSo instead, we add compensating controls. We build monitoring. We write runbooks. We train operators. Each addition reinforces the original design rather than questioning it. We\u0026#39;re not asking \u0026quot;should this system exist in this form?\u0026quot; We\u0026#39;re asking \u0026quot;how do we make this system work?\u0026quot;\u003c/p\u003e\n\u003cp\u003eI\u0026#39;ve sat in meetings where everyone in the room privately knew a system was brittle, but no one said it directly because the system was already in production and replacing it would be a six-month project. Instead, we talked about \u0026quot;hardening\u0026quot; and \u0026quot;resilience improvements\u0026quot;‚Äîlanguage that suggested we were making something robust rather than patching something fundamentally fragile.\u003c/p\u003e\n\u003cp\u003eThe organization\u0026#39;s immune system had learned to reject the observation that the system was designed wrong, because accepting that observation would require acknowledging that a lot of other decisions were also wrong.\u003c/p\u003e\n\u003ch2\u003eMost Failures Are Designed\u003c/h2\u003e\n\u003cp\u003eHere\u0026#39;s an uncomfortable truth: most production failures aren\u0026#39;t accidents. They\u0026#39;re not the result of bugs that slipped through testing or edge cases that no one thought of.\u003c/p\u003e\n\u003cp\u003eThey\u0026#39;re the inevitable outcome of decisions made under constraints.\u003c/p\u003e\n\u003cp\u003eThat temperature monitoring system that lost 96 hours of data? The decision to use flash memory with limited write endurance was made to hit a cost target. The decision to buffer for 72 hours was made based on historical uptime data from a different cellular provider. The decision not to implement hierarchical buffering (edge ‚Üí gateway ‚Üí cloud) was made to keep the architecture simple and shippable.\u003c/p\u003e\n\u003cp\u003eNone of those were wrong decisions in isolation. Given the constraints‚Äîbudget, schedule, what was known at the time‚Äîthey were defensible. Reasonable, even.\u003c/p\u003e\n\u003cp\u003eBut they were decisions, not accidents. And decisions have consequences that aren\u0026#39;t always visible until they compound.\u003c/p\u003e\n\u003cp\u003eThis is what I mean when I say most failures are designed. Not that anyone set out to build a fragile system, but that fragility is often the natural result of optimizing for other things: speed, cost, simplicity, familiarity.\u003c/p\u003e\n\u003cp\u003eThe difference between a bug and a decision is that bugs can be fixed. Decisions are encoded into the architecture. They become load-bearing assumptions. You can\u0026#39;t fix them without rethinking the system.\u003c/p\u003e\n\u003cp\u003eWhen an incident review concludes \u0026quot;the system worked as designed, but we didn\u0026#39;t anticipate this scenario,\u0026quot; what they\u0026#39;re really saying is: \u0026quot;we made tradeoffs, and this is what we traded away.\u0026quot;\u003c/p\u003e\n\u003cp\u003eThe question is whether we\u0026#39;re honest about what we\u0026#39;re trading. Most of the time, we\u0026#39;re not‚Äîbecause being honest would make it harder to get the design approved.\u003c/p\u003e\n\u003ch2\u003eWhy Test, Staging, and Simulation Always Mislead\u003c/h2\u003e\n\u003cp\u003eEvery environment before production is a curated experience.\u003c/p\u003e\n\u003cp\u003eTest environments use clean data. Staging uses a subset of production scale. Simulations use models that abstract away complexity. Even load testing is fundamentally artificial‚Äîyou generate the load, you choose when to apply it, you know what you\u0026#39;re testing for.\u003c/p\u003e\n\u003cp\u003eThis isn\u0026#39;t a criticism of testing. Testing is essential. But it\u0026#39;s also fundamentally limited, and we consistently underestimate how limited it is.\u003c/p\u003e\n\u003cp\u003eHere\u0026#39;s what test environments can\u0026#39;t show you:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThey can\u0026#39;t show you emergent behavior.\u003c/strong\u003e That interaction between the VFD noise and the CAN bus that only manifests when both systems are under load and the ambient temperature is above 30¬∞C? Your test bench runs at 22¬∞C with one system at a time.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThey can\u0026#39;t show you operational reality.\u003c/strong\u003e The operator who learned that if you cycle the power on the HMI in a specific sequence, you can temporarily bypass an error condition that otherwise requires a maintenance window? They discovered that in production, under pressure, when the line manager was demanding a workaround.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThey can\u0026#39;t show you the full dependency graph.\u003c/strong\u003e You tested integration with the ERP system. You didn\u0026#39;t test integration with the ERP system while the network team is doing maintenance and traffic is rerouting through a secondary path with higher latency and the backup MES is handling requests because the primary is being patched.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThey can\u0026#39;t show you time.\u003c/strong\u003e That sensor calibration drift that takes six months to become problematic? Your acceptance test runs for six hours.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThey can\u0026#39;t show you organizational dynamics.\u003c/strong\u003e Who gets called when something ambiguous happens at 2 AM? Who has the authority to make the call to shut down the line? Who actually knows where the documentation is? None of that exists in staging.\u003c/p\u003e\n\u003cp\u003eProduction is the only environment where all the variables are real, all at once, without anyone curating the experience.\u003c/p\u003e\n\u003ch2\u003eWhat Production Pressure Reveals That Design Never Does\u003c/h2\u003e\n\u003cp\u003eThere\u0026#39;s a specific kind of knowledge that only emerges under production pressure, and it has nothing to do with technical design.\u003c/p\u003e\n\u003cp\u003eIt\u0026#39;s the knowledge of what actually matters.\u003c/p\u003e\n\u003cp\u003eIn design, everything matters equally. Every requirement is important. Every failure mode is worth handling. Every dependency is documented. But in production, under time pressure, with costs accumulating, you discover very quickly what\u0026#39;s truly critical and what was just conceptually important.\u003c/p\u003e\n\u003cp\u003eYou discover that the \u0026quot;critical\u0026quot; alert that fires three times a day gets ignored, while the informal message in Slack from the night shift operator gets immediate attention because everyone knows that operator only speaks up when something is genuinely wrong.\u003c/p\u003e\n\u003cp\u003eYou discover that the official escalation path‚Äîsubmit a ticket, wait for triage, get assigned to the on-call engineer‚Äîis too slow, and there\u0026#39;s an unofficial path where certain people have certain phone numbers and that\u0026#39;s what actually gets used when things are breaking.\u003c/p\u003e\n\u003cp\u003eYou discover that the monitoring dashboard everyone insisted on building never gets looked at during incidents, but everyone opens the same three SSH sessions to check the same three log files because that\u0026#39;s where the useful information actually lives.\u003c/p\u003e\n\u003cp\u003eYou discover that the runbook that took weeks to write is useless because it assumes you have time to read it, and in production you don\u0026#39;t‚Äîso people fall back on intuition, pattern matching, and educated guesses.\u003c/p\u003e\n\u003cp\u003eNone of this is visible during design because design happens in an environment where time is less expensive and mistakes are reversible. Production pressure doesn\u0026#39;t just reveal technical problems. It reveals organizational truth.\u003c/p\u003e\n\u003cp\u003eIt shows you which abstractions hold up and which ones collapse. It shows you where authority actually lies versus where the org chart says it lies. It shows you which skills matter‚Äîand they\u0026#39;re often not the ones that got people promoted.\u003c/p\u003e\n\u003ch2\u003eWhat This Means for How We Design\u003c/h2\u003e\n\u003cp\u003eI\u0026#39;m not arguing that we should abandon design reviews or testing or staging environments. They serve a purpose. The problem is that we treat them as validation rather than exploration.\u003c/p\u003e\n\u003cp\u003eWe treat passing a design review as evidence that the design is good. It\u0026#39;s not. It\u0026#39;s evidence that the design is defensible given what we know now, in this room, without production pressure.\u003c/p\u003e\n\u003cp\u003eWe treat staging as a high-fidelity simulation of production. It\u0026#39;s not. It\u0026#39;s a curated environment that shares some properties with production and systematically excludes others.\u003c/p\u003e\n\u003cp\u003eIf we were honest about this, we\u0026#39;d design differently. We\u0026#39;d spend less energy trying to anticipate every failure mode and more energy building systems that can be understood and modified when inevitably surprising failures occur.\u003c/p\u003e\n\u003cp\u003eWe\u0026#39;d document not just what the system does, but what we assumed about the environment it operates in. Not as a CYA exercise, but as a genuine artifact that helps the next person understand what we were thinking‚Äîand where we were probably wrong.\u003c/p\u003e\n\u003cp\u003eWe\u0026#39;d treat the first six months in production not as \u0026quot;stabilization\u0026quot; but as \u0026quot;learning what we actually built\u0026quot;‚Äîbecause that\u0026#39;s what it is.\u003c/p\u003e\n\u003cp\u003eThe happy path isn\u0026#39;t useless. It\u0026#39;s necessary to ship anything at all. But it\u0026#39;s a lie we tell ourselves to make progress in the face of uncertainty.\u003c/p\u003e\n\u003cp\u003eThe question is whether we remember it\u0026#39;s a lie‚Äîor whether we start believing it.\u003c/p\u003e\n\u003cp\u003eBecause the system will tell the truth eventually.\u003c/p\u003e\n\u003cp\u003eIt always does.\u003c/p\u003e\n","rawContent":"\r\nThree engineers sit in a design review for a new temperature monitoring system. The architecture is clean: sensors report to edge controllers, controllers aggregate to a gateway, gateway publishes to the cloud. Redundancy at every layer. Graceful degradation clearly marked on the diagram.\r\n\r\nSomeone asks: \"What happens if the gateway loses connectivity?\"\r\n\r\n\"It buffers locally for up to 72 hours,\" comes the answer. \"More than enough for any reasonable outage.\"\r\n\r\nEveryone nods. The design is approved.\r\n\r\nTwo years later, a cellular provider pushes a configuration update that breaks connectivity for five days. The gateway's flash memory fills in eighteen hours. When connectivity returns, 96 hours of critical temperature data is gone. The system worked exactly as designed‚Äîit just wasn't designed for this.\r\n\r\nThe happy path is seductive because it lets us move forward. But it's also a lie we tell ourselves, and design reviews are where that lie gets institutionalized.\r\n\r\n## Why Design Reviews Reward Optimism\r\n\r\nDesign reviews are supposed to find problems. In practice, they often do the opposite: they create consensus around the assumption that problems won't happen.\r\n\r\nHere's how it works:\r\n\r\nYou present a design. You show the nominal flow. You mark the error paths. You explain the redundancies. And then the questions come‚Äîbut they come in a specific form: \"What if X fails?\" You answer with your contingency for X. \"What if Y happens?\" You show your handling of Y.\r\n\r\nEach question asked and answered creates the illusion that you've covered the space of possible failures. What's harder to see is the space of failures that weren't asked about‚Äînot because they're impossible, but because they're hard to imagine from a conference room.\r\n\r\nThe cellular configuration update that breaks connectivity for five days isn't a question anyone asks, because connectivity outages are supposed to last hours, not days. The sensor that doesn't fail cleanly but drifts slowly enough to stay within acceptance bounds for months isn't on the checklist, because sensors are supposed to either work or fail obviously. The operator who learns to bypass an interlock because it trips too often during valid operations isn't in the room, because we're reviewing technical design, not operational reality.\r\n\r\nDesign reviews optimize for demonstrable coverage of known failure modes. They reward the ability to show that you've thought about things. But \"thinking about things\" is different from designing for them, and both are different from experiencing them.\r\n\r\nThis creates a subtle bias: the designs that pass review most easily are the ones that look most robust on paper. Clean boundaries. Clear error handling. Documented assumptions. The designs that acknowledge fundamental uncertainties‚Äî\"we don't know how operators will actually use this,\" \"we can't predict how this will interact with the legacy system at scale\"‚Äîfeel incomplete. They sound like excuses.\r\n\r\nSo we learn to present certainty. We learn to have answers. And slowly, the happy path becomes the only path we're willing to defend.\r\n\r\n## How Organizations Institutionalize Blind Spots\r\n\r\nIndividual engineers know the happy path is optimistic. But organizations have a way of turning individual caution into collective blindness.\r\n\r\nConsider what happens after that design review. The design is approved. It goes into a requirements document. The requirements become tasks. The tasks become sprints. And at each translation, something is lost.\r\n\r\nThe subtle caveat‚Äî\"this assumes network partitions are transient\"‚Äîbecomes \"handles network failures.\" The hedge‚Äî\"buffering capacity should be sufficient for typical outages\"‚Äîbecomes \"72-hour buffer.\" The uncertainty‚Äî\"we'll need to monitor how this behaves under load\"‚Äîbecomes a checkbox: \"performance tested.\"\r\n\r\nThis isn't malice. It's how organizations create actionable plans from ambiguous reality. But in the process, assumptions get promoted to facts, and facts get encoded into architecture.\r\n\r\nWorse, once something is designed and built, it becomes expensive to question. Not just financially expensive‚Äîpolitically expensive. The team that built it has invested in it. Managers have reported progress on it. Customers have been promised it. To say \"we need to rethink this\" is to say all that investment might have been misdirected.\r\n\r\nSo instead, we add compensating controls. We build monitoring. We write runbooks. We train operators. Each addition reinforces the original design rather than questioning it. We're not asking \"should this system exist in this form?\" We're asking \"how do we make this system work?\"\r\n\r\nI've sat in meetings where everyone in the room privately knew a system was brittle, but no one said it directly because the system was already in production and replacing it would be a six-month project. Instead, we talked about \"hardening\" and \"resilience improvements\"‚Äîlanguage that suggested we were making something robust rather than patching something fundamentally fragile.\r\n\r\nThe organization's immune system had learned to reject the observation that the system was designed wrong, because accepting that observation would require acknowledging that a lot of other decisions were also wrong.\r\n\r\n## Most Failures Are Designed\r\n\r\nHere's an uncomfortable truth: most production failures aren't accidents. They're not the result of bugs that slipped through testing or edge cases that no one thought of.\r\n\r\nThey're the inevitable outcome of decisions made under constraints.\r\n\r\nThat temperature monitoring system that lost 96 hours of data? The decision to use flash memory with limited write endurance was made to hit a cost target. The decision to buffer for 72 hours was made based on historical uptime data from a different cellular provider. The decision not to implement hierarchical buffering (edge ‚Üí gateway ‚Üí cloud) was made to keep the architecture simple and shippable.\r\n\r\nNone of those were wrong decisions in isolation. Given the constraints‚Äîbudget, schedule, what was known at the time‚Äîthey were defensible. Reasonable, even.\r\n\r\nBut they were decisions, not accidents. And decisions have consequences that aren't always visible until they compound.\r\n\r\nThis is what I mean when I say most failures are designed. Not that anyone set out to build a fragile system, but that fragility is often the natural result of optimizing for other things: speed, cost, simplicity, familiarity.\r\n\r\nThe difference between a bug and a decision is that bugs can be fixed. Decisions are encoded into the architecture. They become load-bearing assumptions. You can't fix them without rethinking the system.\r\n\r\nWhen an incident review concludes \"the system worked as designed, but we didn't anticipate this scenario,\" what they're really saying is: \"we made tradeoffs, and this is what we traded away.\"\r\n\r\nThe question is whether we're honest about what we're trading. Most of the time, we're not‚Äîbecause being honest would make it harder to get the design approved.\r\n\r\n## Why Test, Staging, and Simulation Always Mislead\r\n\r\nEvery environment before production is a curated experience.\r\n\r\nTest environments use clean data. Staging uses a subset of production scale. Simulations use models that abstract away complexity. Even load testing is fundamentally artificial‚Äîyou generate the load, you choose when to apply it, you know what you're testing for.\r\n\r\nThis isn't a criticism of testing. Testing is essential. But it's also fundamentally limited, and we consistently underestimate how limited it is.\r\n\r\nHere's what test environments can't show you:\r\n\r\n**They can't show you emergent behavior.** That interaction between the VFD noise and the CAN bus that only manifests when both systems are under load and the ambient temperature is above 30¬∞C? Your test bench runs at 22¬∞C with one system at a time.\r\n\r\n**They can't show you operational reality.** The operator who learned that if you cycle the power on the HMI in a specific sequence, you can temporarily bypass an error condition that otherwise requires a maintenance window? They discovered that in production, under pressure, when the line manager was demanding a workaround.\r\n\r\n**They can't show you the full dependency graph.** You tested integration with the ERP system. You didn't test integration with the ERP system while the network team is doing maintenance and traffic is rerouting through a secondary path with higher latency and the backup MES is handling requests because the primary is being patched.\r\n\r\n**They can't show you time.** That sensor calibration drift that takes six months to become problematic? Your acceptance test runs for six hours.\r\n\r\n**They can't show you organizational dynamics.** Who gets called when something ambiguous happens at 2 AM? Who has the authority to make the call to shut down the line? Who actually knows where the documentation is? None of that exists in staging.\r\n\r\nProduction is the only environment where all the variables are real, all at once, without anyone curating the experience.\r\n\r\n## What Production Pressure Reveals That Design Never Does\r\n\r\nThere's a specific kind of knowledge that only emerges under production pressure, and it has nothing to do with technical design.\r\n\r\nIt's the knowledge of what actually matters.\r\n\r\nIn design, everything matters equally. Every requirement is important. Every failure mode is worth handling. Every dependency is documented. But in production, under time pressure, with costs accumulating, you discover very quickly what's truly critical and what was just conceptually important.\r\n\r\nYou discover that the \"critical\" alert that fires three times a day gets ignored, while the informal message in Slack from the night shift operator gets immediate attention because everyone knows that operator only speaks up when something is genuinely wrong.\r\n\r\nYou discover that the official escalation path‚Äîsubmit a ticket, wait for triage, get assigned to the on-call engineer‚Äîis too slow, and there's an unofficial path where certain people have certain phone numbers and that's what actually gets used when things are breaking.\r\n\r\nYou discover that the monitoring dashboard everyone insisted on building never gets looked at during incidents, but everyone opens the same three SSH sessions to check the same three log files because that's where the useful information actually lives.\r\n\r\nYou discover that the runbook that took weeks to write is useless because it assumes you have time to read it, and in production you don't‚Äîso people fall back on intuition, pattern matching, and educated guesses.\r\n\r\nNone of this is visible during design because design happens in an environment where time is less expensive and mistakes are reversible. Production pressure doesn't just reveal technical problems. It reveals organizational truth.\r\n\r\nIt shows you which abstractions hold up and which ones collapse. It shows you where authority actually lies versus where the org chart says it lies. It shows you which skills matter‚Äîand they're often not the ones that got people promoted.\r\n\r\n## What This Means for How We Design\r\n\r\nI'm not arguing that we should abandon design reviews or testing or staging environments. They serve a purpose. The problem is that we treat them as validation rather than exploration.\r\n\r\nWe treat passing a design review as evidence that the design is good. It's not. It's evidence that the design is defensible given what we know now, in this room, without production pressure.\r\n\r\nWe treat staging as a high-fidelity simulation of production. It's not. It's a curated environment that shares some properties with production and systematically excludes others.\r\n\r\nIf we were honest about this, we'd design differently. We'd spend less energy trying to anticipate every failure mode and more energy building systems that can be understood and modified when inevitably surprising failures occur.\r\n\r\nWe'd document not just what the system does, but what we assumed about the environment it operates in. Not as a CYA exercise, but as a genuine artifact that helps the next person understand what we were thinking‚Äîand where we were probably wrong.\r\n\r\nWe'd treat the first six months in production not as \"stabilization\" but as \"learning what we actually built\"‚Äîbecause that's what it is.\r\n\r\nThe happy path isn't useless. It's necessary to ship anything at all. But it's a lie we tell ourselves to make progress in the face of uncertainty.\r\n\r\nThe question is whether we remember it's a lie‚Äîor whether we start believing it.\r\n\r\nBecause the system will tell the truth eventually.\r\n\r\nIt always does."}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"the-happy-post-lie"},"buildId":"phl_WOpLyX2gCvGrSm1hh","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>